{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/27 23:10:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/27 23:10:55 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "|2016-01-01|        DL|             1248|   DTW| LAX|        1935|  1935.0|      0.0|    23.0|    1958.0|   2107.0|   13.0|        2144|  2120.0|    -24.0|      0.0|     0.0|           309.0|              285.0|   249.0|  1979.0|\n",
      "|2016-01-01|        DL|             1251|   ATL| GRR|        2125|  2130.0|      5.0|    13.0|    2143.0|   2315.0|    4.0|        2321|  2319.0|     -2.0|      0.0|     0.0|           116.0|              109.0|    92.0|   640.0|\n",
      "|2016-01-01|        DL|             1254|   LAX| ATL|        2255|  2256.0|      1.0|    19.0|    2315.0|    542.0|    5.0|         600|   547.0|    -13.0|      0.0|     0.0|           245.0|              231.0|   207.0|  1947.0|\n",
      "|2016-01-01|        DL|             1255|   SLC| ATL|        1656|  1700.0|      4.0|    12.0|    1712.0|   2205.0|    8.0|        2229|  2213.0|    -16.0|      0.0|     0.0|           213.0|              193.0|   173.0|  1590.0|\n",
      "|2016-01-01|        DL|             1256|   BZN| MSP|         900|  1012.0|     72.0|    63.0|    1115.0|   1416.0|    4.0|        1216|  1420.0|    124.0|      0.0|     0.0|           136.0|              188.0|   121.0|   874.0|\n",
      "|2016-01-01|        DL|             1257|   ATL| BNA|        1233|  1356.0|     83.0|    22.0|    1418.0|   1356.0|    6.0|        1239|  1402.0|     83.0|      0.0|     0.0|            66.0|               66.0|    38.0|   214.0|\n",
      "|2016-01-01|        DL|             1257|   BNA| ATL|        1320|  1446.0|     86.0|    15.0|    1501.0|   1638.0|    6.0|        1530|  1644.0|     74.0|      0.0|     0.0|            70.0|               58.0|    37.0|   214.0|\n",
      "|2016-01-01|        DL|             1258|   ATL| JAX|         945|   946.0|      1.0|    19.0|    1005.0|   1050.0|    3.0|        1050|  1053.0|      3.0|      0.0|     0.0|            65.0|               67.0|    45.0|   270.0|\n",
      "|2016-01-01|        DL|             1258|   JAX| ATL|        1145|  1144.0|     -1.0|    12.0|    1156.0|   1239.0|    8.0|        1302|  1247.0|    -15.0|      0.0|     0.0|            77.0|               63.0|    43.0|   270.0|\n",
      "|2016-01-01|        DL|             1259|   ATL| OKC|        2110|  2107.0|     -3.0|    16.0|    2123.0|   2219.0|    5.0|        2236|  2224.0|    -12.0|      0.0|     0.0|           146.0|              137.0|   116.0|   761.0|\n",
      "|2016-01-01|        DL|             1260|   MSP| SMF|        1115|  1113.0|     -2.0|    12.0|    1125.0|   1232.0|    4.0|        1309|  1236.0|    -33.0|      0.0|     0.0|           234.0|              203.0|   187.0|  1517.0|\n",
      "|2016-01-01|        DL|             1262|   LAX| JFK|        2255|  2248.0|     -7.0|    23.0|    2311.0|    650.0|   11.0|         715|   701.0|    -14.0|      0.0|     0.0|           320.0|              313.0|   279.0|  2475.0|\n",
      "|2016-01-01|        DL|             1263|   ATL| MDT|        1510|  1509.0|     -1.0|    17.0|    1526.0|   1646.0|    5.0|        1702|  1651.0|    -11.0|      0.0|     0.0|           112.0|              102.0|    80.0|   620.0|\n",
      "|2016-01-01|        DL|             1263|   MDT| ATL|        1737|  1727.0|    -10.0|    11.0|    1738.0|   1923.0|   11.0|        1949|  1934.0|    -15.0|      0.0|     0.0|           132.0|              127.0|   105.0|   620.0|\n",
      "|2016-01-01|        DL|             1264|   SLC| JFK|        2345|  2341.0|     -4.0|    25.0|       6.0|    602.0|   11.0|         607|   613.0|      6.0|      0.0|     0.0|           262.0|              272.0|   236.0|  1990.0|\n",
      "|2016-01-01|        DL|             1265|   SAV| ATL|        1408|  1403.0|     -5.0|    15.0|    1418.0|   1459.0|    6.0|        1523|  1505.0|    -18.0|      0.0|     0.0|            75.0|               62.0|    41.0|   214.0|\n",
      "|2016-01-01|        DL|             1266|   BUF| ATL|         615|   612.0|     -3.0|    38.0|     650.0|    844.0|    5.0|         843|   849.0|      6.0|      0.0|     0.0|           148.0|              157.0|   114.0|   712.0|\n",
      "|2016-01-01|        DL|             1269|   LGA| MIA|        1100|  1100.0|      0.0|    15.0|    1115.0|   1402.0|    4.0|        1432|  1406.0|    -26.0|      0.0|     0.0|           212.0|              186.0|   167.0|  1096.0|\n",
      "|2016-01-01|        DL|             1270|   ATL| PNS|        1340|  1337.0|     -3.0|    11.0|    1348.0|   1339.0|    3.0|        1352|  1342.0|    -10.0|      0.0|     0.0|            72.0|               65.0|    51.0|   271.0|\n",
      "|2016-01-01|        DL|             1270|   PNS| ATL|        1435|  1431.0|     -4.0|    10.0|    1441.0|   1622.0|    6.0|        1648|  1628.0|    -20.0|      0.0|     0.0|            73.0|               57.0|    41.0|   271.0|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"CSV Reader\").getOrCreate()\n",
    "\n",
    "# Read the CSV file\n",
    "csv_file_path = \"Airline_Delay_2016-2018.csv\"  # Replace with your CSV file path\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows of the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Análisis de valores nulos ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+-------------+----------------+\n",
      "|columna            |tipo_de_dato|valores_nulos|porcentaje_nulos|\n",
      "+-------------------+------------+-------------+----------------+\n",
      "|FL_DATE            |date        |0            |0.0             |\n",
      "|OP_CARRIER         |string      |0            |0.0             |\n",
      "|OP_CARRIER_FL_NUM  |int         |0            |0.0             |\n",
      "|ORIGIN             |string      |0            |0.0             |\n",
      "|DEST               |string      |0            |0.0             |\n",
      "|CRS_DEP_TIME       |int         |0            |0.0             |\n",
      "|DEP_TIME           |double      |256081       |1.38            |\n",
      "|DEP_DELAY          |double      |261033       |1.41            |\n",
      "|TAXI_OUT           |double      |263393       |1.42            |\n",
      "|WHEELS_OFF         |double      |263388       |1.42            |\n",
      "|WHEELS_ON          |double      |271764       |1.47            |\n",
      "|TAXI_IN            |double      |271764       |1.47            |\n",
      "|CRS_ARR_TIME       |int         |0            |0.0             |\n",
      "|ARR_TIME           |double      |271763       |1.47            |\n",
      "|ARR_DELAY          |double      |311764       |1.68            |\n",
      "|CANCELLED          |double      |0            |0.0             |\n",
      "|DIVERTED           |double      |0            |0.0             |\n",
      "|CRS_ELAPSED_TIME   |double      |23           |0.0             |\n",
      "|ACTUAL_ELAPSED_TIME|double      |309166       |1.67            |\n",
      "|AIR_TIME           |double      |309166       |1.67            |\n",
      "+-------------------+------------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Análisis estadístico de columnas numéricas ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+---------------------+--------------------+------+------+\n",
      "|columna            |count      |mean                 |stddev              |min   |max   |\n",
      "+-------------------+-----------+---------------------+--------------------+------+------+\n",
      "|OP_CARRIER_FL_NUM  |1.8505725E7|2304.635922451025    |1792.0299765876928  |1.0   |8402.0|\n",
      "|CRS_DEP_TIME       |1.8505725E7|1330.1731464722404   |490.5252390971099   |1.0   |2359.0|\n",
      "|DEP_TIME           |1.8249644E7|1333.743058385139    |503.8671257420324   |1.0   |2400.0|\n",
      "|DEP_DELAY          |1.8244692E7|9.580880017048246    |43.04881783465609   |-234.0|2755.0|\n",
      "|TAXI_OUT           |1.8242332E7|16.84608404232529    |9.441980050787464   |0.0   |196.0 |\n",
      "|WHEELS_OFF         |1.8242337E7|1356.3663577753223   |505.54272649540945  |1.0   |2400.0|\n",
      "|WHEELS_ON          |1.8233961E7|1464.4559408677028   |532.6591688699245   |1.0   |2400.0|\n",
      "|TAXI_IN            |1.8233961E7|7.527830952364108    |5.90965625624773    |0.0   |414.0 |\n",
      "|CRS_ARR_TIME       |1.8505725E7|1488.6100139281223   |517.9177700612927   |1.0   |2400.0|\n",
      "|ARR_TIME           |1.8233962E7|1468.883535953404    |537.0026090785647   |1.0   |2400.0|\n",
      "|ARR_DELAY          |1.8193961E7|4.361593662864288    |45.11875035221143   |-238.0|2692.0|\n",
      "|CANCELLED          |1.8505725E7|0.014327350049781891 |0.1188363490412439  |0.0   |1.0   |\n",
      "|DIVERTED           |1.8505725E7|0.0023798581249856463|0.048725707060911456|0.0   |1.0   |\n",
      "|CRS_ELAPSED_TIME   |1.8505702E7|144.22530115312566   |75.50062013999326   |-99.0 |718.0 |\n",
      "|ACTUAL_ELAPSED_TIME|1.8196559E7|139.22770200673654   |75.0379914641269    |14.0  |784.0 |\n",
      "|AIR_TIME           |1.8196559E7|114.86600911743808   |72.88150170691291   |4.0   |723.0 |\n",
      "|DISTANCE           |1.8505725E7|832.5811463749732    |613.3905504323635   |25.0  |4983.0|\n",
      "+-------------------+-----------+---------------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum, round as spark_round\n",
    "\n",
    "# =====================\n",
    "# PARTE 1: Valores nulos\n",
    "# =====================\n",
    "\n",
    "# 1. Número total de registros\n",
    "total_rows = df.count()\n",
    "\n",
    "# 2. Obtener tipos de datos\n",
    "data_types = dict(df.dtypes)\n",
    "\n",
    "# 3. Contar valores nulos por columna\n",
    "missing_exprs = [\n",
    "    spark_sum(col(c).isNull().cast(\"int\")).alias(c) \n",
    "    for c in df.columns\n",
    "]\n",
    "\n",
    "missing_df = df.select(missing_exprs)\n",
    "missing_counts = missing_df.collect()[0].asDict()\n",
    "\n",
    "# 4. Crear un DataFrame resumen de valores nulos\n",
    "nulls_data = []\n",
    "for col_name in df.columns:\n",
    "    n_missing = missing_counts[col_name]\n",
    "    pct_missing = (n_missing / total_rows) * 100\n",
    "    dtype = data_types[col_name]\n",
    "    nulls_data.append((col_name, dtype, n_missing, round(pct_missing, 2)))\n",
    "\n",
    "nulls_schema = [\"columna\", \"tipo_de_dato\", \"valores_nulos\", \"porcentaje_nulos\"]\n",
    "nulls_df = spark.createDataFrame(nulls_data, schema=nulls_schema)\n",
    "\n",
    "# Mostrar resultados de valores nulos\n",
    "print(\"==== Análisis de valores nulos ====\")\n",
    "nulls_df.show(n=nulls_df.count(), truncate=False)\n",
    "\n",
    "# ==============================\n",
    "# PARTE 2: Análisis Estadístico\n",
    "# ==============================\n",
    "\n",
    "# 1. Seleccionar columnas numéricas\n",
    "numeric_columns = [name for name, dtype in df.dtypes if dtype in ('int', 'double', 'float', 'bigint', 'smallint')]\n",
    "\n",
    "if numeric_columns:\n",
    "    # 2. Aplicar describe() solo a numéricas\n",
    "    describe_df = df.select([col(c) for c in numeric_columns]).describe()\n",
    "\n",
    "    # 3. Transformar describe_df a formato vertical\n",
    "    metric_names = describe_df.select(\"summary\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    stats_data = []\n",
    "    for col_name in numeric_columns:\n",
    "        values = describe_df.select(col_name).rdd.flatMap(lambda x: x).collect()\n",
    "        metric_dict = dict(zip(metric_names, values))\n",
    "        stats_row = (\n",
    "            col_name,\n",
    "            float(metric_dict.get(\"count\", 0)),\n",
    "            float(metric_dict.get(\"mean\", 0)),\n",
    "            float(metric_dict.get(\"stddev\", 0)),\n",
    "            float(metric_dict.get(\"min\", 0)),\n",
    "            float(metric_dict.get(\"max\", 0))\n",
    "        )\n",
    "        stats_data.append(stats_row)\n",
    "\n",
    "    stats_schema = [\"columna\", \"count\", \"mean\", \"stddev\", \"min\", \"max\"]\n",
    "    stats_df = spark.createDataFrame(stats_data, schema=stats_schema)\n",
    "\n",
    "    # Mostrar resultados estadísticos\n",
    "    print(\"\\n==== Análisis estadístico de columnas numéricas ====\")\n",
    "    nulls_df.show(n=nulls_df.count(), truncate=False)\n",
    "else:\n",
    "    print(\"\\nNo hay columnas numéricas para análisis estadístico.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
