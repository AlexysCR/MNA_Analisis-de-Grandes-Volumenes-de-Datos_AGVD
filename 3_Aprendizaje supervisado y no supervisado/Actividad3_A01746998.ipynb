{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNl8G3vHkPSX"
   },
   "source": [
    "# **Maestría en Inteligencia Artificial Aplicada**\n",
    "\n",
    "## Curso: **Análisis de grandes volúmenes de datos (Gpo 10)**\n",
    "\n",
    "### Tecnológico de Monterrey\n",
    "\n",
    "## Actividad 3\n",
    "\n",
    "###  Aprendizaje supervisado y no supervisado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U69mHA6i201G"
   },
   "source": [
    "#### **Nombrey matrícula**\n",
    "\n",
    "*   **A01746998** - Alexys Martín Coate Reyes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c34ZOnna3Gu"
   },
   "source": [
    "# **1. Introducción teórica**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfZZ0stLmWJN"
   },
   "source": [
    "# **2. Selección de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: double (nullable = true)\n",
      " |-- WHEELS_ON: double (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      "\n",
      "Número total de registros: 18505725\n"
     ]
    }
   ],
   "source": [
    "# Crear sesión Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"EDA_Vuelos\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Leer el CSV\n",
    "df = spark.read.csv(\"../Dataset/Airline_Delay_2016-2018.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Mostrar esquema de datos\n",
    "df.printSchema()\n",
    "\n",
    "# Número total de registros\n",
    "total_registros = df.count()\n",
    "print(f\"Número total de registros: {total_registros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "|2016-01-01|        DL|             1248|   DTW| LAX|        1935|  1935.0|      0.0|    23.0|    1958.0|   2107.0|   13.0|        2144|  2120.0|    -24.0|      0.0|     0.0|           309.0|              285.0|   249.0|  1979.0|\n",
      "|2016-01-01|        DL|             1251|   ATL| GRR|        2125|  2130.0|      5.0|    13.0|    2143.0|   2315.0|    4.0|        2321|  2319.0|     -2.0|      0.0|     0.0|           116.0|              109.0|    92.0|   640.0|\n",
      "|2016-01-01|        DL|             1254|   LAX| ATL|        2255|  2256.0|      1.0|    19.0|    2315.0|    542.0|    5.0|         600|   547.0|    -13.0|      0.0|     0.0|           245.0|              231.0|   207.0|  1947.0|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimiendo los 3 primeros rengloes del dataframe dataframe\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionando variables de caracterización "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OP_CARRIER 18\n",
      "ORIGIN 362\n",
      "DEST 360\n",
      "CANCELLED 2\n",
      "DIVERTED 2\n"
     ]
    }
   ],
   "source": [
    "# Variables seleccionadas\n",
    "vars_particion = [\"OP_CARRIER\", \"ORIGIN\", \"DEST\", \"CANCELLED\", \"DIVERTED\"]\n",
    "\n",
    "# Imrpimiendo la cantidad de valores únicos que se tiene por las columnas seleccionadas\n",
    "for col in vars_particion:\n",
    "    print(col, df.select(col).distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+---------+--------+-----+---------------------+\n",
      "|OP_CARRIER|ORIGIN|DEST|CANCELLED|DIVERTED|count|probabilidad         |\n",
      "+----------+------+----+---------+--------+-----+---------------------+\n",
      "|EV        |ATL   |AGS |0.0      |0.0     |2912 |1.573567098830227E-4 |\n",
      "|EV        |DTW   |BWI |0.0      |0.0     |23   |1.2428586288837644E-6|\n",
      "|EV        |BRO   |IAH |0.0      |0.0     |3054 |1.6503001098308766E-4|\n",
      "|F9        |DEN   |MIA |0.0      |0.0     |1089 |5.884665421106171E-5 |\n",
      "|WN        |BDL   |RSW |0.0      |0.0     |735  |3.971743879258986E-5 |\n",
      "|WN        |BWI   |MEM |0.0      |0.0     |1348 |7.284232311892671E-5 |\n",
      "|WN        |DEN   |BOS |0.0      |0.0     |2467 |1.3331009728070637E-4|\n",
      "|WN        |LAX   |LAS |0.0      |0.0     |10922|5.901957367247162E-4 |\n",
      "|WN        |LAX   |SAT |0.0      |0.0     |2056 |1.1110075395587041E-4|\n",
      "|WN        |MCO   |CMH |0.0      |0.0     |3558 |1.922648261551493E-4 |\n",
      "|WN        |PIT   |DEN |0.0      |0.0     |1307 |7.062679251961218E-5 |\n",
      "|WN        |BNA   |MDW |0.0      |0.0     |6764 |3.6550851155520793E-4|\n",
      "|OO        |PSC   |DEN |0.0      |0.0     |2005 |1.083448500396499E-4 |\n",
      "|EV        |ORD   |MEM |0.0      |0.0     |504  |2.7234815172061618E-5|\n",
      "|OO        |JAC   |SLC |0.0      |0.0     |626  |3.382736963831463E-5 |\n",
      "|OO        |DCA   |ORD |0.0      |0.0     |3871 |2.091785109743066E-4 |\n",
      "|UA        |IAD   |LAS |0.0      |0.0     |2045 |1.1050634330727383E-4|\n",
      "|UA        |CMH   |DEN |0.0      |0.0     |911  |4.922800917013519E-5 |\n",
      "|AA        |LGA   |MIA |0.0      |0.0     |11569|6.251578903285334E-4 |\n",
      "|AA        |CLT   |SFO |0.0      |0.0     |5664 |3.060674466955496E-4 |\n",
      "+----------+------+----+---------+--------+-----+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, round\n",
    "\n",
    "# Calcular frecuencia de combinaciones\n",
    "combinaciones = df.groupBy(vars_particion).count()\n",
    "\n",
    "# Total de registros\n",
    "total = df.count()\n",
    "\n",
    "# Agregar probabilidad\n",
    "combinaciones = combinaciones.withColumn(\"probabilidad\", col(\"count\") / total)\n",
    "\n",
    "combinaciones.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+---------+--------+-----+---------------------+--------------+\n",
      "|OP_CARRIER|ORIGIN|DEST|CANCELLED|DIVERTED|count|probabilidad         |tamaño_muestra|\n",
      "+----------+------+----+---------+--------+-----+---------------------+--------------+\n",
      "|HA        |OGG   |HNL |0.0      |0.0     |28891|0.0015611925498730799|289           |\n",
      "|HA        |HNL   |OGG |0.0      |0.0     |28830|0.0015578962726399534|288           |\n",
      "|HA        |KOA   |HNL |0.0      |0.0     |21350|0.0011536970315942769|213           |\n",
      "|HA        |HNL   |KOA |0.0      |0.0     |20673|0.0011171137580397417|207           |\n",
      "|HA        |HNL   |LIH |0.0      |0.0     |19946|0.0010778286179006767|199           |\n",
      "|HA        |LIH   |HNL |0.0      |0.0     |19901|0.0010753969379745998|199           |\n",
      "|WN        |DAL   |HOU |0.0      |0.0     |19109|0.0010325993712756458|191           |\n",
      "|WN        |HOU   |DAL |0.0      |0.0     |19131|0.0010337881925728389|191           |\n",
      "|DL        |MCO   |ATL |0.0      |0.0     |17524|9.469502005460472E-4 |175           |\n",
      "|DL        |ATL   |MCO |0.0      |0.0     |17524|9.469502005460472E-4 |175           |\n",
      "+----------+------+----+---------+--------+-----+---------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Tamaño total esperado de la muestra final: 183519\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "# Definir tamaño total de la muestra (por ejemplo, 1% del total)\n",
    "tamaño_muestra_total = int(total * 0.01)\n",
    "\n",
    "# Establecer un mínimo de registros por partición\n",
    "minimo_por_particion = 0\n",
    "\n",
    "# Calcular el tamaño de muestra por partición según su probabilidad\n",
    "combinaciones_con_tamaño = combinaciones.withColumn(\n",
    "    \"tamaño_muestra\",\n",
    "    round(\n",
    "        when(\n",
    "            (col(\"probabilidad\") * tamaño_muestra_total) < minimo_por_particion,\n",
    "            lit(minimo_por_particion)\n",
    "        ).otherwise(col(\"probabilidad\") * tamaño_muestra_total)\n",
    "    ).cast(\"int\")\n",
    ")\n",
    "\n",
    "# Ordenar para visualizar mejor\n",
    "combinaciones_con_tamaño = combinaciones_con_tamaño.orderBy(col(\"tamaño_muestra\").desc())\n",
    "\n",
    "combinaciones_con_tamaño.show(10, truncate=False)\n",
    "\n",
    "# Calcular el tamaño final total de la muestra\n",
    "tamaño_muestra_final = combinaciones_con_tamaño.agg({\"tamaño_muestra\": \"sum\"}).collect()[0][0]\n",
    "\n",
    "print(f\"Tamaño total esperado de la muestra final: {tamaño_muestra_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+---------+--------+----------+-----------------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+----------------+-------------------+--------+--------+--------------+-------+\n",
      "|OP_CARRIER|ORIGIN|DEST|CANCELLED|DIVERTED|FL_DATE   |OP_CARRIER_FL_NUM|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|tamaño_muestra|row_num|\n",
      "+----------+------+----+---------+--------+----------+-----------------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+----------------+-------------------+--------+--------+--------------+-------+\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-01-01|3296             |855         |854.0   |-1.0     |12.0    |906.0     |939.0    |3.0    |953         |942.0   |-11.0    |58.0            |48.0               |33.0    |143.0   |10            |1      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-01|3680             |1355        |1534.0  |99.0     |14.0    |1548.0    |1633.0   |3.0    |1445        |1636.0  |111.0    |50.0            |62.0               |45.0    |143.0   |10            |2      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-02|3366             |1746        |1752.0  |6.0      |18.0    |1810.0    |1840.0   |3.0    |1845        |1843.0  |-2.0     |59.0            |51.0               |30.0    |143.0   |10            |3      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-02|3809             |2134        |2132.0  |-2.0     |19.0    |2151.0    |2221.0   |5.0    |2232        |2226.0  |-6.0     |58.0            |54.0               |30.0    |143.0   |10            |4      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-03|3354             |1026        |1019.0  |-7.0     |21.0    |1040.0    |1111.0   |4.0    |1122        |1115.0  |-7.0     |56.0            |56.0               |31.0    |143.0   |10            |5      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-03|3366             |1746        |1826.0  |40.0     |12.0    |1838.0    |1908.0   |5.0    |1842        |1913.0  |31.0     |56.0            |47.0               |30.0    |143.0   |10            |6      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-03|3904             |2234        |2228.0  |-6.0     |16.0    |2244.0    |2319.0   |4.0    |2327        |2323.0  |-4.0     |53.0            |55.0               |35.0    |143.0   |10            |7      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-04|3366             |1746        |1745.0  |-1.0     |21.0    |1806.0    |1833.0   |4.0    |1845        |1837.0  |-8.0     |59.0            |52.0               |27.0    |143.0   |10            |8      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-04|3809             |2134        |2130.0  |-4.0     |19.0    |2149.0    |2218.0   |4.0    |2232        |2222.0  |-10.0    |58.0            |52.0               |29.0    |143.0   |10            |9      |\n",
      "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-05|3366             |1746        |1749.0  |3.0      |21.0    |1810.0    |1839.0   |4.0    |1845        |1843.0  |-2.0     |59.0            |54.0               |29.0    |143.0   |10            |10     |\n",
      "+----------+------+----+---------+--------+----------+-----------------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+----------------+-------------------+--------+--------+--------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Tamaño total de la muestra: 183519\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Unir el tamaño de muestra a cada combinación en el dataset original\n",
    "df_con_muestra = df.join(\n",
    "    combinaciones_con_tamaño.select(*vars_particion, \"tamaño_muestra\"),\n",
    "    on=vars_particion,\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Crear ventana ordenada por fecha y hora dentro de cada combinación\n",
    "ventana = Window.partitionBy(*vars_particion).orderBy(\"FL_DATE\", \"CRS_DEP_TIME\")\n",
    "\n",
    "# Enumerar vuelos por combinación (ordenados por tiempo)\n",
    "df_con_muestra = df_con_muestra.withColumn(\"row_num\", row_number().over(ventana))\n",
    "\n",
    "# Filtrar solo los primeros N registros por combinación\n",
    "muestra_final = df_con_muestra.filter(col(\"row_num\") <= col(\"tamaño_muestra\"))\n",
    "\n",
    "# Mostrar la muestra final\n",
    "muestra_final.show(10, truncate=False)\n",
    "\n",
    "print(f\"Tamaño total de la muestra: {muestra_final.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfZZ0stLmWJN"
   },
   "source": [
    "# **3. Preparación de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables importantes para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizará un análisis de predicción para saber que tanto un avión se retrasará. Por ello se quitarán las columnas que no aportan mucha información para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>...</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>tamaño_muestra</th>\n",
       "      <th>row_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AGS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3296</td>\n",
       "      <td>855</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>953</td>\n",
       "      <td>942.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AGS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3680</td>\n",
       "      <td>1355</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AGS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>3366</td>\n",
       "      <td>1746</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1845</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AGS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>3809</td>\n",
       "      <td>2134</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2232</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AGS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-03-03</td>\n",
       "      <td>3354</td>\n",
       "      <td>1026</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>2266</td>\n",
       "      <td>640</td>\n",
       "      <td>632.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>951</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>116</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>1410</td>\n",
       "      <td>815</td>\n",
       "      <td>813.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1138</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>116</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>1103</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1321</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>116</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>1082</td>\n",
       "      <td>1100</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1421</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>116</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>1311</td>\n",
       "      <td>1220</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1543</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>116</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    OP_CARRIER ORIGIN DEST  CANCELLED  DIVERTED     FL_DATE  \\\n",
       "0           9E    ATL  AGS        0.0       0.0  2018-01-01   \n",
       "1           9E    ATL  AGS        0.0       0.0  2018-03-01   \n",
       "2           9E    ATL  AGS        0.0       0.0  2018-03-02   \n",
       "3           9E    ATL  AGS        0.0       0.0  2018-03-02   \n",
       "4           9E    ATL  AGS        0.0       0.0  2018-03-03   \n",
       "..         ...    ...  ...        ...       ...         ...   \n",
       "995         AA    LGA  MIA        0.0       0.0  2016-01-07   \n",
       "996         AA    LGA  MIA        0.0       0.0  2016-01-07   \n",
       "997         AA    LGA  MIA        0.0       0.0  2016-01-07   \n",
       "998         AA    LGA  MIA        0.0       0.0  2016-01-07   \n",
       "999         AA    LGA  MIA        0.0       0.0  2016-01-07   \n",
       "\n",
       "     OP_CARRIER_FL_NUM  CRS_DEP_TIME  DEP_TIME  DEP_DELAY  ...  TAXI_IN  \\\n",
       "0                 3296           855     854.0       -1.0  ...      3.0   \n",
       "1                 3680          1355    1534.0       99.0  ...      3.0   \n",
       "2                 3366          1746    1752.0        6.0  ...      3.0   \n",
       "3                 3809          2134    2132.0       -2.0  ...      5.0   \n",
       "4                 3354          1026    1019.0       -7.0  ...      4.0   \n",
       "..                 ...           ...       ...        ...  ...      ...   \n",
       "995               2266           640     632.0       -8.0  ...     58.0   \n",
       "996               1410           815     813.0       -2.0  ...     44.0   \n",
       "997               1103          1000    1000.0        0.0  ...      5.0   \n",
       "998               1082          1100    1103.0        3.0  ...      7.0   \n",
       "999               1311          1220    1214.0       -6.0  ...      6.0   \n",
       "\n",
       "     CRS_ARR_TIME  ARR_TIME  ARR_DELAY  CRS_ELAPSED_TIME  ACTUAL_ELAPSED_TIME  \\\n",
       "0             953     942.0      -11.0              58.0                 48.0   \n",
       "1            1445    1636.0      111.0              50.0                 62.0   \n",
       "2            1845    1843.0       -2.0              59.0                 51.0   \n",
       "3            2232    2226.0       -6.0              58.0                 54.0   \n",
       "4            1122    1115.0       -7.0              56.0                 56.0   \n",
       "..            ...       ...        ...               ...                  ...   \n",
       "995           951    1027.0       36.0             191.0                235.0   \n",
       "996          1138    1152.0       14.0             203.0                219.0   \n",
       "997          1321    1247.0      -34.0             201.0                167.0   \n",
       "998          1421    1356.0      -25.0             201.0                173.0   \n",
       "999          1543    1508.0      -35.0             203.0                174.0   \n",
       "\n",
       "     AIR_TIME  DISTANCE  tamaño_muestra  row_num  \n",
       "0        33.0     143.0              10        1  \n",
       "1        45.0     143.0              10        2  \n",
       "2        30.0     143.0              10        3  \n",
       "3        30.0     143.0              10        4  \n",
       "4        31.0     143.0              10        5  \n",
       "..        ...       ...             ...      ...  \n",
       "995     158.0    1096.0             116       66  \n",
       "996     157.0    1096.0             116       67  \n",
       "997     147.0    1096.0             116       68  \n",
       "998     151.0    1096.0             116       69  \n",
       "999     152.0    1096.0             116       70  \n",
       "\n",
       "[1000 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pandas_df = muestra_final.limit(50).toPandas()\n",
    "display(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una nueva columna para verificar si \n",
    "delayed_time = 10\n",
    "df_muestra = muestra_final.withColumn(\"DELAYED\", when(df.ARR_DELAY > delayed_time, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+----+------------+------------+----------------+--------+---------+---------+-------+\n",
      "|   FL_DATE|OP_CARRIER|ORIGIN|DEST|CRS_DEP_TIME|CRS_ARR_TIME|CRS_ELAPSED_TIME|DISTANCE|CANCELLED|ARR_DELAY|DELAYED|\n",
      "+----------+----------+------+----+------------+------------+----------------+--------+---------+---------+-------+\n",
      "|2018-01-01|        9E|   ATL| AGS|         855|         953|            58.0|   143.0|      0.0|    -11.0|      0|\n",
      "|2018-03-01|        9E|   ATL| AGS|        1355|        1445|            50.0|   143.0|      0.0|    111.0|      1|\n",
      "|2018-03-02|        9E|   ATL| AGS|        1746|        1845|            59.0|   143.0|      0.0|     -2.0|      0|\n",
      "|2018-03-02|        9E|   ATL| AGS|        2134|        2232|            58.0|   143.0|      0.0|     -6.0|      0|\n",
      "|2018-03-03|        9E|   ATL| AGS|        1026|        1122|            56.0|   143.0|      0.0|     -7.0|      0|\n",
      "|2018-03-03|        9E|   ATL| AGS|        1746|        1842|            56.0|   143.0|      0.0|     31.0|      1|\n",
      "|2018-03-03|        9E|   ATL| AGS|        2234|        2327|            53.0|   143.0|      0.0|     -4.0|      0|\n",
      "|2018-03-04|        9E|   ATL| AGS|        1746|        1845|            59.0|   143.0|      0.0|     -8.0|      0|\n",
      "|2018-03-04|        9E|   ATL| AGS|        2134|        2232|            58.0|   143.0|      0.0|    -10.0|      0|\n",
      "|2018-03-05|        9E|   ATL| AGS|        1746|        1845|            59.0|   143.0|      0.0|     -2.0|      0|\n",
      "|2018-05-01|        9E|   ATL| GRB|        1403|        1515|           132.0|   774.0|      0.0|    -11.0|      0|\n",
      "|2018-05-01|        9E|   ATL| GRB|        2013|        2125|           132.0|   774.0|      0.0|     -9.0|      0|\n",
      "|2018-05-02|        9E|   ATL| GRB|        1403|        1515|           132.0|   774.0|      0.0|    -12.0|      0|\n",
      "|2018-01-01|        9E|   ATL| ILM|         819|         943|            84.0|   377.0|      0.0|    -19.0|      0|\n",
      "|2018-01-01|        9E|   ATL| ILM|        1610|        1734|            84.0|   377.0|      0.0|    -10.0|      0|\n",
      "|2018-01-01|        9E|   ATL| ILM|        2210|        2331|            81.0|   377.0|      0.0|    -10.0|      0|\n",
      "|2018-01-02|        9E|   ATL| ILM|         819|         943|            84.0|   377.0|      0.0|    -22.0|      0|\n",
      "|2018-01-02|        9E|   ATL| ILM|        1235|        1358|            83.0|   377.0|      0.0|    -12.0|      0|\n",
      "|2018-01-02|        9E|   ATL| ILM|        1610|        1734|            84.0|   377.0|      0.0|     47.0|      1|\n",
      "|2018-04-03|        9E|   ATL| ILM|        1259|        1420|            81.0|   377.0|      0.0|    -11.0|      0|\n",
      "+----------+----------+------+----+------------+------------+----------------+--------+---------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variables a descartar\n",
    "cols_to_drop = [\"tamaño_muestra\", \"row_num\", \"OP_CARRIER_FL_NUM\", \"DEP_TIME\",\"DEP_DELAY\", \"TAXI_OUT\", \n",
    "                \"WHEELS_OFF\", \"WHEELS_ON\", \"TAXI_IN\" , \"ARR_TIME\", \"ARR_DELAY\", \"DIVERTED\", \"ACTUAL_ELAPSED_TIME\", \"AIR_TIME\"]\n",
    "\n",
    "# Variables importantes para el modelo\n",
    "selected_cols = [\n",
    "    \"FL_DATE\", \"OP_CARRIER\", \"ORIGIN\", \"DEST\",\n",
    "    \"CRS_DEP_TIME\", \"CRS_ARR_TIME\", \"CRS_ELAPSED_TIME\",\n",
    "    \"DISTANCE\", \"CANCELLED\", \"ARR_DELAY\", \"DELAYED\"\n",
    "]\n",
    "\n",
    "# Realizando la selección de columnas importantes como datos de entrenamiento\n",
    "df_raw = df_muestra.select(*selected_cols)\n",
    "df_raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indexer \u001b[38;5;129;01min\u001b[39;00m indexers:\n\u001b[1;32m---> 19\u001b[0m     df_transformed \u001b[38;5;241m=\u001b[39m indexer\u001b[38;5;241m.\u001b[39mfit(df_transformed)\u001b[38;5;241m.\u001b[39mtransform(df_transformed)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Eliminando las columnas de las variables categóricas originales\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[1;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_java(dataset)\n\u001b[0;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\u001b[38;5;241m.\u001b[39mfit(dataset\u001b[38;5;241m.\u001b[39m_jdf)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(10061, 'No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión', None, 10061, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2155\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2152\u001b[0m         traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m   2153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_showtraceback(etype, value, stb)\n\u001b[0;32m   2156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[0;32m   2157\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[0;32m   2158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\ipykernel\\zmqshell.py:559\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[1;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[0;32m    553\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    554\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    556\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(evalue),\n\u001b[0;32m    560\u001b[0m }\n\u001b[0;32m    562\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\py4j\\protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[1;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m gateway_client\u001b[38;5;241m.\u001b[39msend_command(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception_cmd)\n\u001b[0;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\py4j\\java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\py4j\\clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_new_connection()\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\py4j\\clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 291\u001b[0m     connection\u001b[38;5;241m.\u001b[39mconnect_to_java_server()\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env-pyspark\\Lib\\site-packages\\py4j\\clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mconnect((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_port))\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dayofweek, month\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Extrayendo el día, mes y eliminando la columna original de fecha\n",
    "df_transformed = df_raw.withColumn(\"FL_DAY_OF_WEEK\", dayofweek(\"FL_DATE\")) \\\n",
    "                     .withColumn(\"FL_MONTH\", month(\"FL_DATE\")) \\\n",
    "                     .drop(\"FL_DATE\") \n",
    "\n",
    "\n",
    "\n",
    "# Codificaando las variables categóricas\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"OP_CARRIER\", outputCol=\"OP_CARRIER_T\"),\n",
    "    StringIndexer(inputCol=\"ORIGIN\", outputCol=\"ORIGIN_T\"),\n",
    "    StringIndexer(inputCol=\"DEST\", outputCol=\"DEST_T\")\n",
    "]\n",
    "\n",
    "for indexer in indexers:\n",
    "    df_transformed = indexer.fit(df_transformed).transform(df_transformed)\n",
    "\n",
    "# Eliminando las columnas de las variables categóricas originales\n",
    "cols_to_drop = [\"OP_CARRIER\", \"ORIGIN\", \"DEST\"]\n",
    "df_transformed = df_transformed.drop(*cols_to_drop) # Using * to unpack the list of column names\n",
    "\n",
    "df_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:/hadoop\"\n",
    "os.environ[\"hadoop.home.dir\"] = \"C:/hadoop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.write.mode(\"overwrite\").parquet(\"./df_transformed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan registros con valores nulos\n",
    "df_clean = df_transformed.dropna()\n",
    "\n",
    "#Se eliminan columnas con valores nulos\n",
    "df_clean = df_clean.na.drop()\n",
    "\n",
    "#Se eliminan registros duplicados\n",
    "df_clean = df_clean.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qjKoEqiqBN1"
   },
   "source": [
    "# **4. Prepraración del conjunto de entrenamiento y prueba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"OP_CARRIER_T\",\"ORIGIN_T\",\"DEST_T\",\n",
    "        \"CRS_DEP_TIME\",\"CRS_ARR_TIME\",\"CRS_ELAPSED_TIME\",\n",
    "        \"DISTANCE\",\"CANCELLED\",\n",
    "        \"FL_DAY_OF_WEEK\", \"FL_MONTH\"\n",
    "        #\"ARR_DELAY\",\"DELAYED\"\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "df_vector = assembler.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos de entrenamiento y prueba\n",
    "df_train, df_val_test = df_vector.randomSplit([0.7, 0.3], seed=42)\n",
    "df_val, df_test = df_val_test.randomSplit([0.5, 0.5], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RS0Hxj25vTWh"
   },
   "source": [
    "# **5. Construcción de modelos de aprendizaje supervisado y no supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Supervisado - Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"DELAYED\")\n",
    "lr_model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo No Supervisado - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4c34ZOnna3Gu",
    "MfZZ0stLmWJN",
    "ygchEdcKqIzU",
    "1qjKoEqiqBN1",
    "RS0Hxj25vTWh",
    "ToqRl7fT_fn2",
    "W4S7q0yR0Mpi",
    "pibp1LA91CP_",
    "WDIiSHvg0_hm",
    "NbhBUBKJp1MB",
    "YCkh2WfN1MC1"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
