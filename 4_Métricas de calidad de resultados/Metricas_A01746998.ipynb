{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNl8G3vHkPSX"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## Curso: **Análisis de grandes volúmenes de datos (Gpo 10)**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "## **Actividad 4**\n",
        "\n",
        "###  *Métricas de calidad de resultados*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U69mHA6i201G"
      },
      "source": [
        "#### **Nombrey matrícula**\n",
        "\n",
        "*   **A01746998** - Alexys Martín Coate Reyes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c34ZOnna3Gu"
      },
      "source": [
        "# **1. Construcción de la muestra M**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d99IfLm-Kvgk"
      },
      "source": [
        "### Cargando los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EWqkks-FKvgk"
      },
      "outputs": [],
      "source": [
        "# Librerias\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_-sM5wAiKvgl",
        "outputId": "2e9e6660-2a27-4401-fea2-eb3df2e7afc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- FL_DATE: date (nullable = true)\n",
            " |-- OP_CARRIER: string (nullable = true)\n",
            " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
            " |-- ORIGIN: string (nullable = true)\n",
            " |-- DEST: string (nullable = true)\n",
            " |-- CRS_DEP_TIME: integer (nullable = true)\n",
            " |-- DEP_TIME: double (nullable = true)\n",
            " |-- DEP_DELAY: double (nullable = true)\n",
            " |-- TAXI_OUT: double (nullable = true)\n",
            " |-- WHEELS_OFF: double (nullable = true)\n",
            " |-- WHEELS_ON: double (nullable = true)\n",
            " |-- TAXI_IN: double (nullable = true)\n",
            " |-- CRS_ARR_TIME: integer (nullable = true)\n",
            " |-- ARR_TIME: double (nullable = true)\n",
            " |-- ARR_DELAY: double (nullable = true)\n",
            " |-- CANCELLED: double (nullable = true)\n",
            " |-- DIVERTED: double (nullable = true)\n",
            " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
            " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
            " |-- AIR_TIME: double (nullable = true)\n",
            " |-- DISTANCE: double (nullable = true)\n",
            "\n",
            "Número total de registros: 18505725\n"
          ]
        }
      ],
      "source": [
        "# Crear sesión Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"EDA_Vuelos\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Leer el CSV\n",
        "df = spark.read.csv(\"./Airline_Delay_2016-2018.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Mostrar esquema de datos\n",
        "df.printSchema()\n",
        "\n",
        "# Número total de registros\n",
        "total_registros = df.count()\n",
        "print(f\"Número total de registros: {total_registros}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-d0qHEIuKvgl",
        "outputId": "a0d6faa7-b27f-452e-f835-0d7fe21c1c5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
            "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|\n",
            "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
            "|2016-01-01|        DL|             1248|   DTW| LAX|        1935|  1935.0|      0.0|    23.0|    1958.0|   2107.0|   13.0|        2144|  2120.0|    -24.0|      0.0|     0.0|           309.0|              285.0|   249.0|  1979.0|\n",
            "|2016-01-01|        DL|             1251|   ATL| GRR|        2125|  2130.0|      5.0|    13.0|    2143.0|   2315.0|    4.0|        2321|  2319.0|     -2.0|      0.0|     0.0|           116.0|              109.0|    92.0|   640.0|\n",
            "|2016-01-01|        DL|             1254|   LAX| ATL|        2255|  2256.0|      1.0|    19.0|    2315.0|    542.0|    5.0|         600|   547.0|    -13.0|      0.0|     0.0|           245.0|              231.0|   207.0|  1947.0|\n",
            "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Imprimiendo los 3 primeros rengloes del dataframe dataframe\n",
        "df.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acuerdo con los datos analizados anteriormente concluimos que podemos crear un modelo que regresión que prediga el retraso de los aviones, teniendo como variable objetivo ARR_DELAY.\n",
        "\n",
        "Conforme a esto procedemos a realizar la selección de variables de caracterización para este problema, que consiste en seleccionar las varibles más importantes para la modelación del problema."
      ],
      "metadata": {
        "id": "HppPF0nLeHTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analizando los distintos tipos de datos dentro del dataframe"
      ],
      "metadata": {
        "id": "X_f3uOrzpDxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de columnas\n",
        "columnas = df.columns\n",
        "\n",
        "# Mapear tipos de datos\n",
        "tipo_columnas = dict(df.dtypes)\n",
        "# Conteo de CANCELLED\n",
        "print(\"=== Conteo de CANCELLED ===\")\n",
        "df.groupBy(\"CANCELLED\").count().show()\n",
        "\n",
        "# Conteo de DIVERTED\n",
        "print(\"=== Conteo de DIVERTED ===\")\n",
        "df.groupBy(\"DIVERTED\").count().show()"
      ],
      "metadata": {
        "id": "1DYkcJlFpDcQ",
        "outputId": "8a0d6182-bf9f-4279-af65-9dffc43ee1a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Conteo de CANCELLED ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizar cada columna\n",
        "for columna in columnas:\n",
        "    print(f\"\\n=== Análisis de columna: {columna} ===\")\n",
        "\n",
        "    tipo_dato = tipo_columnas[columna]\n",
        "\n",
        "    if tipo_dato in ['double', 'float']:\n",
        "        # Nulos y NaNs para numéricas flotantes\n",
        "        nulos = df.filter((col(columna).isNull()) | (isnan(col(columna)))).count()\n",
        "    else:\n",
        "        # Solo nulos (y vacíos para strings) para otros tipos\n",
        "        nulos = df.filter((col(columna).isNull()) | (col(columna) == \"\")).count()\n",
        "\n",
        "    print(f\"Valores nulos o vacíos: {nulos}\")\n",
        "\n",
        "    # Número de valores únicos\n",
        "    distintos = df.select(columna).distinct().count()\n",
        "    print(f\"Valores únicos: {distintos}\")\n",
        "\n",
        "    # Análisis según tipo de dato\n",
        "    if tipo_dato in ['int', 'bigint', 'double', 'float']:\n",
        "        resumen = df.select(\n",
        "            min(columna).alias(\"Minimo\"),\n",
        "            max(columna).alias(\"Maximo\"),\n",
        "            avg(columna).alias(\"Promedio\")\n",
        "        ).collect()[0]\n",
        "        print(f\"Min: {resumen['Minimo']}, Max: {resumen['Maximo']}, Promedio: {resumen['Promedio']:.2f}\")\n",
        "\n",
        "    elif tipo_dato in ['string', 'date', 'timestamp']:\n",
        "        print(\"Top 5 valores más frecuentes:\")\n",
        "        top5 = df.groupBy(columna).count().orderBy(desc(\"count\")).limit(5)\n",
        "        top5.show(truncate=False)"
      ],
      "metadata": {
        "id": "Ukt6O3KppJE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV0wngonKvgl"
      },
      "source": [
        "### Seleccionando variables de caracterización"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variables relacionadas con el tiempo:**\n",
        "\n",
        "* `FL_DATE`: La fecha del vuelo puede ser importante para identificar patrones estacionales o días de la semana con mayor probabilidad de retraso.\n",
        "\n",
        "* `CRS_DEP_TIME`: La hora programada de salida puede influir en los retrasos (por ejemplo, vuelos en horas pico).\n",
        "\n",
        "* `DEP_TIME`: La hora real de salida. La diferencia entre  `DEP_TIME` y `CRS_DEP_TIME` (`DEP_DELAY`) es una variable predictora muy fuerte para `ARR_DELAY`.\n",
        "\n",
        "* `TAXI_OUT`: El tiempo que tarda el avión en rodar desde la puerta de embarque hasta la pista de despegue. Tiempos de taxi largos pueden indicar congestión o problemas.\n",
        "\n",
        "* `WHEELS_OFF`: La hora en que las ruedas del avión dejan el suelo. Relacionado con `TAXI_OUT` y `DEP_TIME`.\n",
        "\n",
        "* `WHEELS_ON`: La hora en que las ruedas del avión tocan tierra. Relacionado con `AIR_TIME` y `TAXI_IN`.\n",
        "\n",
        "* `TAXI_IN`: El tiempo que tarda el avión en rodar desde la pista de aterrizaje hasta la puerta de embarque.\n",
        "\n",
        "\n",
        "\n",
        "**Variables operacionales y de ruta:**\n",
        "\n",
        "* `OP_CARRIER`: La aerolínea operadora. Algunas aerolíneas pueden tener una mayor propensión a sufrir retrasos.\n",
        "\n",
        "* `ORIGIN`: El aeropuerto de origen. Ciertos aeropuertos pueden experimentar más retrasos debido a su tamaño, ubicación geográfica o congestión.\n",
        "\n",
        "* `DEST`: El aeropuerto de destino. Similar al aeropuerto de origen.\n",
        "\n",
        "* `DISTANCE`: La distancia del vuelo. Los vuelos de larga distancia podrían ser más susceptibles a retrasos acumulados.\n",
        "\n",
        "* `OP_CARRIER_FL_NUM`: El número de vuelo. Podría usarse para identificar rutas específicas o vuelos recurrentes con historiales de retraso.\n",
        "\n",
        "\n",
        "\n",
        "**Variables de duración del vuelo:**\n",
        "\n",
        "* `CRS_ELAPSED_TIME`: El tiempo de vuelo programado.\n",
        "\n",
        "* `ACTUAL_ELAPSED_TIME`: El tiempo de vuelo real. La diferencia con `CRS_ELAPSED_TIME` está directamente relacionada con `ARR_DELAY`.\n",
        "\n",
        "* `AIR_TIME`: El tiempo que el avión pasa en el aire."
      ],
      "metadata": {
        "id": "h_K-48Chh_3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si nosotros queremos predecir el delay del avión, habrá variables que desconozcamos ya que la estimación se deberá de realizar antes y/o después del despegue del avión.\n",
        "\n",
        "Tomando esto en cuenta no podemos utilizar las siguientes variables:\n",
        "\n",
        "* `AIR_TIME`\n",
        "* `ACTUAL_ELAPSED_TIME`"
      ],
      "metadata": {
        "id": "x8CZWyfAkes5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AzOdDfDKvgm",
        "outputId": "a703228f-18aa-4916-a347-59c1ed02be53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OP_CARRIER 18\n",
            "ORIGIN 362\n",
            "DEST 360\n",
            "CANCELLED 2\n",
            "DIVERTED 2\n"
          ]
        }
      ],
      "source": [
        "# Variables seleccionadas\n",
        "vars_particion = [\"OP_CARRIER\", \"ORIGIN\", \"DEST\", \"CANCELLED\", \"DIVERTED\"]\n",
        "\n",
        "# Imrpimiendo la cantidad de valores únicos que se tiene por las columnas seleccionadas\n",
        "for col in vars_particion:\n",
        "    print(col, df.select(col).distinct().count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsrLmz8vKvgm",
        "outputId": "3f0f8734-54a8-4d61-ce93-2e573948ca39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------+----+---------+--------+-----+---------------------+\n",
            "|OP_CARRIER|ORIGIN|DEST|CANCELLED|DIVERTED|count|probabilidad         |\n",
            "+----------+------+----+---------+--------+-----+---------------------+\n",
            "|EV        |ATL   |AGS |0.0      |0.0     |2912 |1.573567098830227E-4 |\n",
            "|EV        |DTW   |BWI |0.0      |0.0     |23   |1.2428586288837644E-6|\n",
            "|EV        |BRO   |IAH |0.0      |0.0     |3054 |1.6503001098308766E-4|\n",
            "|F9        |DEN   |MIA |0.0      |0.0     |1089 |5.884665421106171E-5 |\n",
            "|WN        |BDL   |RSW |0.0      |0.0     |735  |3.971743879258986E-5 |\n",
            "|WN        |BWI   |MEM |0.0      |0.0     |1348 |7.284232311892671E-5 |\n",
            "|WN        |DEN   |BOS |0.0      |0.0     |2467 |1.3331009728070637E-4|\n",
            "|WN        |LAX   |LAS |0.0      |0.0     |10922|5.901957367247162E-4 |\n",
            "|WN        |LAX   |SAT |0.0      |0.0     |2056 |1.1110075395587041E-4|\n",
            "|WN        |MCO   |CMH |0.0      |0.0     |3558 |1.922648261551493E-4 |\n",
            "|WN        |PIT   |DEN |0.0      |0.0     |1307 |7.062679251961218E-5 |\n",
            "|WN        |BNA   |MDW |0.0      |0.0     |6764 |3.6550851155520793E-4|\n",
            "|OO        |PSC   |DEN |0.0      |0.0     |2005 |1.083448500396499E-4 |\n",
            "|EV        |ORD   |MEM |0.0      |0.0     |504  |2.7234815172061618E-5|\n",
            "|OO        |JAC   |SLC |0.0      |0.0     |626  |3.382736963831463E-5 |\n",
            "|OO        |DCA   |ORD |0.0      |0.0     |3871 |2.091785109743066E-4 |\n",
            "|UA        |IAD   |LAS |0.0      |0.0     |2045 |1.1050634330727383E-4|\n",
            "|UA        |CMH   |DEN |0.0      |0.0     |911  |4.922800917013519E-5 |\n",
            "|AA        |LGA   |MIA |0.0      |0.0     |11569|6.251578903285334E-4 |\n",
            "|AA        |CLT   |SFO |0.0      |0.0     |5664 |3.060674466955496E-4 |\n",
            "+----------+------+----+---------+--------+-----+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, count, round\n",
        "\n",
        "# Calcular frecuencia de combinaciones\n",
        "combinaciones = df.groupBy(vars_particion).count()\n",
        "\n",
        "# Total de registros\n",
        "total = df.count()\n",
        "\n",
        "# Agregar probabilidad\n",
        "combinaciones = combinaciones.withColumn(\"probabilidad\", col(\"count\") / total)\n",
        "\n",
        "combinaciones.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Uk8eWh8Kvgm",
        "outputId": "ec017c63-9f3e-4970-f71a-85b05adcf5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------+----+---------+--------+-----+---------------------+--------------+\n",
            "|OP_CARRIER|ORIGIN|DEST|CANCELLED|DIVERTED|count|probabilidad         |tamaño_muestra|\n",
            "+----------+------+----+---------+--------+-----+---------------------+--------------+\n",
            "|HA        |OGG   |HNL |0.0      |0.0     |28891|0.0015611925498730799|289           |\n",
            "|HA        |HNL   |OGG |0.0      |0.0     |28830|0.0015578962726399534|288           |\n",
            "|HA        |KOA   |HNL |0.0      |0.0     |21350|0.0011536970315942769|213           |\n",
            "|HA        |HNL   |KOA |0.0      |0.0     |20673|0.0011171137580397417|207           |\n",
            "|HA        |HNL   |LIH |0.0      |0.0     |19946|0.0010778286179006767|199           |\n",
            "|HA        |LIH   |HNL |0.0      |0.0     |19901|0.0010753969379745998|199           |\n",
            "|WN        |DAL   |HOU |0.0      |0.0     |19109|0.0010325993712756458|191           |\n",
            "|WN        |HOU   |DAL |0.0      |0.0     |19131|0.0010337881925728389|191           |\n",
            "|DL        |MCO   |ATL |0.0      |0.0     |17524|9.469502005460472E-4 |175           |\n",
            "|DL        |ATL   |MCO |0.0      |0.0     |17524|9.469502005460472E-4 |175           |\n",
            "+----------+------+----+---------+--------+-----+---------------------+--------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Tamaño total esperado de la muestra final: 183519\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when, lit\n",
        "\n",
        "# Definir tamaño total de la muestra (por ejemplo, 1% del total)\n",
        "tamaño_muestra_total = int(total * 0.01)\n",
        "\n",
        "# Establecer un mínimo de registros por partición\n",
        "minimo_por_particion = 0\n",
        "\n",
        "# Calcular el tamaño de muestra por partición según su probabilidad\n",
        "combinaciones_con_tamaño = combinaciones.withColumn(\n",
        "    \"tamaño_muestra\",\n",
        "    round(\n",
        "        when(\n",
        "            (col(\"probabilidad\") * tamaño_muestra_total) < minimo_por_particion,\n",
        "            lit(minimo_por_particion)\n",
        "        ).otherwise(col(\"probabilidad\") * tamaño_muestra_total)\n",
        "    ).cast(\"int\")\n",
        ")\n",
        "\n",
        "# Ordenar para visualizar mejor\n",
        "combinaciones_con_tamaño = combinaciones_con_tamaño.orderBy(col(\"tamaño_muestra\").desc())\n",
        "\n",
        "combinaciones_con_tamaño.show(10, truncate=False)\n",
        "\n",
        "# Calcular el tamaño final total de la muestra\n",
        "tamaño_muestra_final = combinaciones_con_tamaño.agg({\"tamaño_muestra\": \"sum\"}).collect()[0][0]\n",
        "\n",
        "print(f\"Tamaño total esperado de la muestra final: {tamaño_muestra_final}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFBTMvvvKvgm",
        "outputId": "d77c93a6-b401-46a0-d03e-179e32cd17b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------+----+---------+--------+----------+-----------------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+----------------+-------------------+--------+--------+--------------+-------+\n",
            "|OP_CARRIER|ORIGIN|DEST|CANCELLED|DIVERTED|FL_DATE   |OP_CARRIER_FL_NUM|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|tamaño_muestra|row_num|\n",
            "+----------+------+----+---------+--------+----------+-----------------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+----------------+-------------------+--------+--------+--------------+-------+\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-01-01|3296             |855         |854.0   |-1.0     |12.0    |906.0     |939.0    |3.0    |953         |942.0   |-11.0    |58.0            |48.0               |33.0    |143.0   |10            |1      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-01|3680             |1355        |1534.0  |99.0     |14.0    |1548.0    |1633.0   |3.0    |1445        |1636.0  |111.0    |50.0            |62.0               |45.0    |143.0   |10            |2      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-02|3366             |1746        |1752.0  |6.0      |18.0    |1810.0    |1840.0   |3.0    |1845        |1843.0  |-2.0     |59.0            |51.0               |30.0    |143.0   |10            |3      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-02|3809             |2134        |2132.0  |-2.0     |19.0    |2151.0    |2221.0   |5.0    |2232        |2226.0  |-6.0     |58.0            |54.0               |30.0    |143.0   |10            |4      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-03|3354             |1026        |1019.0  |-7.0     |21.0    |1040.0    |1111.0   |4.0    |1122        |1115.0  |-7.0     |56.0            |56.0               |31.0    |143.0   |10            |5      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-03|3366             |1746        |1826.0  |40.0     |12.0    |1838.0    |1908.0   |5.0    |1842        |1913.0  |31.0     |56.0            |47.0               |30.0    |143.0   |10            |6      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-03|3904             |2234        |2228.0  |-6.0     |16.0    |2244.0    |2319.0   |4.0    |2327        |2323.0  |-4.0     |53.0            |55.0               |35.0    |143.0   |10            |7      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-04|3366             |1746        |1745.0  |-1.0     |21.0    |1806.0    |1833.0   |4.0    |1845        |1837.0  |-8.0     |59.0            |52.0               |27.0    |143.0   |10            |8      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-04|3809             |2134        |2130.0  |-4.0     |19.0    |2149.0    |2218.0   |4.0    |2232        |2222.0  |-10.0    |58.0            |52.0               |29.0    |143.0   |10            |9      |\n",
            "|9E        |ATL   |AGS |0.0      |0.0     |2018-03-05|3366             |1746        |1749.0  |3.0      |21.0    |1810.0    |1839.0   |4.0    |1845        |1843.0  |-2.0     |59.0            |54.0               |29.0    |143.0   |10            |10     |\n",
            "+----------+------+----+---------+--------+----------+-----------------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+----------------+-------------------+--------+--------+--------------+-------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Tamaño total de la muestra: 183519\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "# Unir el tamaño de muestra a cada combinación en el dataset original\n",
        "df_con_muestra = df.join(\n",
        "    combinaciones_con_tamaño.select(*vars_particion, \"tamaño_muestra\"),\n",
        "    on=vars_particion,\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "# Crear ventana ordenada por fecha y hora dentro de cada combinación\n",
        "ventana = Window.partitionBy(*vars_particion).orderBy(\"FL_DATE\", \"CRS_DEP_TIME\")\n",
        "\n",
        "# Enumerar vuelos por combinación (ordenados por tiempo)\n",
        "df_con_muestra = df_con_muestra.withColumn(\"row_num\", row_number().over(ventana))\n",
        "\n",
        "# Filtrar solo los primeros N registros por combinación\n",
        "muestra_final = df_con_muestra.filter(col(\"row_num\") <= col(\"tamaño_muestra\"))\n",
        "\n",
        "# Mostrar la muestra final\n",
        "muestra_final.show(10, truncate=False)\n",
        "\n",
        "print(f\"Tamaño total de la muestra: {muestra_final.count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht0Zp4ujLId8"
      },
      "source": [
        "# **2. Construcción Train – Test**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YpXJHk_JX7fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnuXhLQrLNQW"
      },
      "source": [
        "# **3.  Selección de métricas para medir calidad de resultados**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UusGMj7aX6DN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84ChlHlfLNdu"
      },
      "source": [
        "# **4. Entrenamiento de Modelos de Aprendizaje**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ab5nCn2aX4hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F79GIdXALNm3"
      },
      "source": [
        "# **5. Análisis de resultados**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9rWqEXLyX5L9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4MqHFfsKXj0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4c34ZOnna3Gu",
        "MfZZ0stLmWJN",
        "ygchEdcKqIzU",
        "1qjKoEqiqBN1",
        "RS0Hxj25vTWh",
        "ToqRl7fT_fn2",
        "W4S7q0yR0Mpi",
        "pibp1LA91CP_",
        "WDIiSHvg0_hm",
        "NbhBUBKJp1MB",
        "YCkh2WfN1MC1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}